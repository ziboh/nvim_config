local keymaps = require("plugins.llm.keymaps")
local models = require("plugins.llm.models")
local ui = require("plugins.llm.ui")
local api, tbl_deep_extend, env = vim.api, vim.tbl_deep_extend, vim.env

return {
  "Kurama622/llm.nvim",
  dependencies = { "nvim-lua/plenary.nvim", "MunifTanjim/nui.nvim" },
  cmd = { "LLMSessionToggle", "LLMSelectedTextHandler", "LLMAppHandler" },
  config = function()
    api.nvim_set_hl(0, "LlmCmds", { link = "String" })
    local extensions = require("plugins.llm.extensions")
    local opts = {
      prompt = "You are a helpful Chinese assistant.",
      enable_trace = false,
      -- log_level = 1,

      spinner = {
        text = { "󰧞󰧞", "󰧞󰧞", "󰧞󰧞", "󰧞󰧞" },
        hl = "Title",
      },

      prefix = {
        user = { text = "  ", hl = "Title" },
        assistant = { text = "  ", hl = "Added" },
      },

      display = {
        diff = {
          layout = "vertical", -- vertical|horizontal split for default provider
          opts = { "internal", "filler", "closeoff", "algorithm:patience", "followwrap", "linematch:120" },
          provider = "mini_diff", -- default|mini_diff
          -- disable_diagnostic = true,
        },
      },
      lsp = {
        methods = { "definition", "declaration" },
        root_dir = { ".git" },
      },
      web_search = {
        url = "https://api.tavily.com/search",
        fetch_key = env.TAVILY_API_KEY,
        params = {
          auto_parameters = false,
          topic = "general",
          search_depth = "basic",
          chunks_per_source = 3,
          max_results = 3,
          include_answer = true,
          include_raw_content = true,
          include_images = false,
          include_image_descriptions = false,
          include_favicon = false,
        },
      },
      --[[ custom request args ]]
      -- args = [[return {url, "-s", "-N", "-X", "POST", "-H", "Content-Type: application/json", "-H", authorization, "-d", vim.fn.json_encode(body)}]],
      -- history_path = "/tmp/llm-history",
      save_session = true,
      max_history = 15,
      max_history_name_length = 20,
      models = {
        models.ChatGpt,
        models.Deepseek,
        models.Gemini,
        models.ChatGLM,
      },
    }
    for _, conf in pairs({ ui, extensions, keymaps }) do
      opts = tbl_deep_extend("force", opts, conf)
    end
    require("llm").setup(opts)
  end,
  keys = {
    { "<c-g>c", mode = "n", "<cmd>LLMSessionToggle<cr>" },
    { "<leader>tc", mode = "n", "<cmd>LLMAppHandler CommitMsg<cr>", desc = " Generate AI Commit Message" },
    { "<leader>tt", mode = "n", "<cmd>LLMAppHandler Translate<cr>", desc = " AI Translator" },
    { "<leader>ts", mode = { "x", "n" }, "<cmd>LLMAppHandler WordTranslate<cr>", desc = " Word Translate" },
  },
}
